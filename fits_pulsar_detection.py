# -*- coding: utf-8 -*-
"""FITS_Pulsar_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R4VkV2jzxnLaYoIHSeaNkaof2nPpQ40K
"""

# Code to work with Flexible Image Transport System (FITS) files for detecting Pulsars
from astropy.io import fits
import matplotlib.pyplot as plt
import numpy as np
import statistics
import time

def load_fits(fits_file): #returns the brightest pixel position from a FITS file
  img = fits.open(fits_file)[0].data
  img.reshape(200,200)
  pixel_pos = np.unravel_index(np.argmax(img, axis=None), img.shape)
  return pixel_pos

def mean_fits(array): #returns the mean of multiple stacked fits files; useful for attenuating gaussian noise from measurements
  imgs = fits.open(array[0])[0].data
  length = len(array)
  for i in range(1,length):
    imgs = imgs + fits.open(array[i])[0].data
  
  imgs.reshape(200,200) #reform to an array
  imgs = imgs/length
  max_mean = np.max(imgs)
  return imgs

#Since FITS files can be numerous from measurements, and are in 200x200 image files, computational time can rack up rapidly
#below is a function to show time to complete mean calculations given different functions
def time_stat(func, #function to conduct operation (e.g. mean, median, statistics, etc.)
              size, #size of a random array for the operation
              ntrials): #number of iterations
  times = []
  for i in range(ntrials):
    data = np.random.rand(size)
    start = time.perf_counter()
    mean = func(data)
    seconds = time.perf_counter() - start
    times.append(seconds)
  avg_time = sum(times)/ntrials
  return avg_time

#for a more robust understanding of the FITS data, use the median since it is less sensitive to outliers and acts as a more robust statistic
def median_fits(fitsarr): #does the same thing as the mean FITS function, but does it for the median; requires for thoughtful arithmetic
  #conversion all of the arrays into a numpy 3D array for manipulation
  length = len(fitsarr)
  start = time.perf_counter()
  img_arr = fits.open(fitsarr[0])[0].data
  for i in range(1,length):
    data = fits.open(fitsarr[i])[0].data
    img_arr = np.append(img_arr,data,axis=0)
  
  img_arr = np.reshape(img_arr, (-1, 200*200)) #reshape into an array
  img_pix = img_arr.shape[1]
  len_vals = img_arr.shape[0]
  mid = len_vals//2
  cond = len_vals % 2 #shows if there are an even or odd number of values for median calculation
  
  #taking the arrays to make the 2D median array of all of the images
  med_arr = np.zeros(img_pix)
  for j in range(img_pix):
    vals = img_arr[:,j] #makes an array of all the cell orientation values for all cells 
    vals.sort() #sort values from smallest to largest
    if cond == 1: #oddd
      median = vals[mid]
      med_arr[j] = median
    else: #even
      median = (vals[mid]+vals[mid-1])/2
      med_arr[j] = median 
  med_arr = med_arr.reshape(200,200)
  time_taken = time.perf_counter() - start #needed to compare time complexity to the mean function
    
  #calculating the memory
  memory = length*200*200/64
  return (med_arr,time_taken,memory)

#using the naive approach to median calculation needs all data in memory at once. Using a Binapprox method reduces time and space complexity
def median_bins(values, #data in
                numbins): #number of bins; Binapprox uses a histogram approach of the data to approximate the median - need to bin the data
  mean = np.mean(values)
  std = np.std(values)
    
  # Initialise bins
  left_bin = 0 #holds all data less than the mean - 1 std
  bins = np.zeros(numbins)
  bin_width = 2*std/numbins
    
  # Bin values
  for value in values:
    if value < mean - std: #histograms if values are less than the minimum threshold
      left_bin += 1
    elif value < mean + std:
      bin = int((value - (mean - std))/bin_width) #gives position of bin relative to largest threshold (mean + 1std)
      bins[bin] += 1
    # Ignore values above mean + std since they are not pragmatic for the median calculation

  return mean, std, left_bin, bins 


def median_approx(values, numbin):
  # Call median_bins to calculate the mean, std,
  # and bins for the input values
  mean, std, left_bin, bins = median_bins(values, numbin)
    	
  # Position of the middle element
  N = len(values)
  mid = (N + 1)/2 #defines the midpoint where the median is housed

  count = left_bin
  for b, bincount in enumerate(bins):
    count += bincount
    if count >= mid: # Stop when the cumulative count exceeds the midpoint
      break

  width = 2*std/B
  median = mean - std + width*(b + 0.5) #median approximation
  return median